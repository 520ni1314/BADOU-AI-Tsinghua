1、翻转与不翻转
教科书上对于卷积的定义是先翻转再平移，两个函数的卷积，是先将一个函数翻转，然后再滑动叠加。
此文中所讲的信号分析的例子比较形象的告知我们为什么要翻转其中一个函数：https://www.zhihu.com/question/22298352/answer/637156871
数字中定义的卷积，是为了做信号处理等工作定义的运算，所以需要一半反转
而神经网络中的卷积，是为了提取图像特征，只借鉴了加权求和的特点
再有，数学中使用卷积运算的时候，往往卷积核是确定的，但卷积神经网络的卷积核参数初始是随机值，是训练得到的，翻转则没有意义。

2、卷积步长和填充方式
如果不填充原图像，卷积操作后，原图像的大小会变小，因为卷积是加权求和之后代替卷积区域的中心位置。如果步长为1，
原图像大小h*w，，卷积核，大小为f*f，卷积之后图像大小为（h-f+1，w-f+1），一般s大于1.所以卷积后图像变小。
若步长不为1，卷积后图像更小，所以需要卷积时对原图像填充，有三种方式
（1）full：在卷积核和图像相交时就开始卷积，卷积后图像变大（步长等于1的前提下）
（2）same：在卷积核中心和图像相交时开始卷积，卷积后图像大小不变（步长等于1的前提下）
（3）vaild：卷积核全部在图像中才开始卷积，即不进行天聪，卷积后图像变小（步长为1或大于1都变小）

3、通道数
卷积核的通道数=输入图像的通道数：
卷积核的个数=特征种类数=输出图像的通道数

总结：
  （1）假设一个cnn分类图像，一开始输入图像是三通道的彩色图，则卷积核也是三通道，输入图像若是灰度图，卷积核是单通道的，
而经过一次卷积之后（假设有64个卷积核），输出通道数就是（x，y，64）
  （2）若第二次卷积时，输入矩阵维度为（60,50,64），有64个通道
卷积核如果是3*3的，则卷积核的维度是（3,3,64），假设补偿为1，使用vaild不填充，一个卷积核与图像卷积后输出（58,48），
而64个通道去哪了？答：每一个输出由道多通卷积累加并加上偏置项Bias得到的
而如果用128个卷积核去卷积它，表示提取128个不同的特征，卷积之后的输出有128个（58,48,128）

卷积后一般接一个池化层，池化通常使用最大值池化或均值池化，但卷积一样也有步长的概念，但只是求最大值或均值，所以没有参数。
卷积的功能是提取图像的局部特征，训练的目的就是找到一组卷积核参数使得提取到的特征更利于分类或其他任务，使之效果更好。